{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "\n",
    "> *This notebook should work well in the `Python 3 (Data Science)` kernel in SageMaker Studio, or `conda_python3` in SageMaker Notebook Instances*\n",
    "\n",
    "If you ran this Forecast POC in your own account and would like to avoid ongoing charges, run the commands below to cleanup the resources created in the previous notebooks, including:\n",
    "\n",
    "* S3 Bucket\n",
    "* IAM Role\n",
    "* Dataset Group\n",
    "* Datasets\n",
    "* Import Jobs\n",
    "* Predictors\n",
    "* Forecasts\n",
    "* Forecast Export Jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "The cell below will import necessary libraries, retrieve stored variables from previous notebooks, and connect to Forecast, S3, and IAM via the Boto3 Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "from time import sleep\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import botocore.exceptions\n",
    "\n",
    "# Local Dependencies:\n",
    "import util\n",
    "\n",
    "# Retrieve stored variables\n",
    "%store -r\n",
    "\n",
    "# Create connections to Forecast, S3, and IAM\n",
    "session = boto3.Session(region_name=region) \n",
    "forecast = session.client(\"forecast\")\n",
    "iam = session.client(\"iam\")\n",
    "s3 = session.client(\"s3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Objects to Delete\n",
    "\n",
    "The resources we created have to be deleted in a specific order. The cell below will build a recursive inventory of the child objects belonging to our top-level Dataset Group object. We'll then print out everything we plan to delete. Make sure to review this output carefully to ensure it matches up with what you expect to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build inventory of child objects related to DatasetGroup to delete...\n",
    "datasetGroupResponse=forecast.describe_dataset_group(DatasetGroupArn=datasetGroupArn)\n",
    "\n",
    "# Get Datasets belonging to the parent Dataset Group\n",
    "datasetArns=datasetGroupResponse['DatasetArns']\n",
    "\n",
    "# Get Import Jobs belonging to Datasets\n",
    "importJobArns=[]\n",
    "for d in datasetArns:\n",
    "    importJobResponse=forecast.list_dataset_import_jobs(Filters=[\n",
    "        {\n",
    "            'Key': 'DatasetArn',\n",
    "            'Value': d,\n",
    "            'Condition': 'IS' \n",
    "        }\n",
    "    ])\n",
    "    if len(importJobResponse['DatasetImportJobs']) > 0:\n",
    "        importJobArns.append(importJobResponse['DatasetImportJobs'][0]['DatasetImportJobArn'])\n",
    "\n",
    "# Get Predictors belonging to Dataset Group\n",
    "predictorArns=[]\n",
    "predictorResponse=forecast.list_predictors(Filters=[\n",
    "        {\n",
    "            'Key': 'DatasetGroupArn',\n",
    "            'Value': datasetGroupArn,\n",
    "            'Condition': 'IS'\n",
    "        }\n",
    "    ])\n",
    "\n",
    "for p in predictorResponse['Predictors']:\n",
    "    predictorArns.append(p['PredictorArn'])\n",
    "\n",
    "# Get Forecasts belonging to Dataset Group\n",
    "forecastArns=[]\n",
    "forecastResponse=forecast.list_forecasts(Filters=[\n",
    "        {\n",
    "            'Key': 'DatasetGroupArn',\n",
    "            'Value': datasetGroupArn,\n",
    "            'Condition': 'IS'\n",
    "        }\n",
    "    ])\n",
    "\n",
    "for f in forecastResponse['Forecasts']:\n",
    "    forecastArns.append(f['ForecastArn'])\n",
    "    \n",
    "# Get Forecast Export Jobs\n",
    "forecastExportJobArns=[]\n",
    "forecastExportJobResponse=forecast.list_forecast_export_jobs()\n",
    "for fa in forecastArns:\n",
    "    forecastName=fa.split('/')[-1]\n",
    "    for e in forecastExportJobResponse['ForecastExportJobs']:\n",
    "        if forecastName in e['ForecastExportJobArn']:\n",
    "            forecastExportJobArns.append(e['ForecastExportJobArn'])\n",
    "\n",
    "bucket_names = [bucket_name]\n",
    "if bucket_name != export_bucket_name:\n",
    "    bucket_names.append(export_bucket_name)\n",
    "\n",
    "# Print list of resources that will be deleted\n",
    "print(\"The following resources will be deleted if you execute the next cell...\")\n",
    "print(\"\")\n",
    "print(\"S3 Bucket(s): \")\n",
    "for b in bucket_names:\n",
    "    print(b)\n",
    "print(\"\")\n",
    "print(\"IAM Role: \")\n",
    "print(forecast_role_arn)\n",
    "print(\"\")\n",
    "print(\"Dataset Group: \")\n",
    "print(datasetGroupArn)\n",
    "print(\"\")\n",
    "print(\"Datasets: \")\n",
    "for d in datasetArns:\n",
    "    print(d)\n",
    "print(\"\")\n",
    "print(\"Import Jobs: \")\n",
    "for i in importJobArns:\n",
    "    print(i)\n",
    "print(\"\")\n",
    "print(\"Predictors: \")\n",
    "for p in predictorArns:\n",
    "    print(p)\n",
    "print(\"\")\n",
    "print(\"Forecasts: \")\n",
    "for f in forecastArns:\n",
    "    print(f)\n",
    "print(\"\")\n",
    "print(\"Forecast Export Jobs: \")\n",
    "for e in forecastExportJobArns:\n",
    "    print(e)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Forecast Objects\n",
    "\n",
    "Once you've verified that the inventory of resources listed above is safe to delete, run the cell below to delete the Forecast resources. This cell will run the delete commands asyncronously and will print \"Successful delete\" for each object it deletes. The full deletion typically takes around 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the Forecast Export Jobs:\n",
    "for e in forecastExportJobArns:\n",
    "    util.wait_till_delete(lambda: forecast.delete_forecast_export_job(ForecastExportJobArn=e))\n",
    "\n",
    "# Delete the Forecasts\n",
    "for f in forecastArns:\n",
    "    util.wait_till_delete(lambda: forecast.delete_forecast(ForecastArn=f))\n",
    "\n",
    "# Delete the Predictors\n",
    "for p in predictorArns:\n",
    "    util.wait_till_delete(lambda: forecast.delete_predictor(PredictorArn=p))\n",
    "\n",
    "# Delete the Import Jobs\n",
    "for i in importJobArns:\n",
    "    util.wait_till_delete(lambda: forecast.delete_dataset_import_job(DatasetImportJobArn=i))\n",
    "\n",
    "# Delete the Datasets\n",
    "for d in datasetArns:\n",
    "    util.wait_till_delete(lambda: forecast.delete_dataset(DatasetArn=d))\n",
    "\n",
    "# Delete the Dataset Group\n",
    "util.wait_till_delete(lambda: forecast.delete_dataset_group(DatasetGroupArn=datasetGroupArn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm Forecast Objects are Deleted\n",
    "\n",
    "We'll know the cell above is done asychronously deleting child objects once the top-level Dataset Group parent object is deleted. Run the cell below, and wait until you get a \"Forecast objects succesfully deleted\" message before proceeding further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop on describe_dataset_group\n",
    "while True:\n",
    "    try:\n",
    "        responseStatus=forecast.describe_dataset_group(DatasetGroupArn=datasetGroupArn)['Status']\n",
    "        print(responseStatus)\n",
    "        sleep(10)\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        # When given the resource not found exception, deletion has occured\n",
    "        if e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            print('Forecast objects succesfully deleted')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete IAM and S3 Objects\n",
    "\n",
    "Now that the Forecast objects are cleaned up, we can delete the rest of the IAM and S3 resources we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_role_name = role_arn.split(\"/\")[-1]\n",
    "\n",
    "# Detach Role Policies from the IAM Role\n",
    "# NOTE: Doesn't delete policies, if you created any custom ones!\n",
    "attached_policies_response = iam.list_attached_role_policies(RoleName=forecast_role_name)\n",
    "for policy in attached_policies_response[\"AttachedPolicies\"]:\n",
    "    iam.detach_role_policy(RoleName=forecast_role_name, PolicyArn=policy[\"PolicyArn\"])\n",
    "\n",
    "# Delete the IAM Role    \n",
    "iam.delete_role(RoleName=forecast_role_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in bucket_names:\n",
    "    # Delete all objects from the S3 Bucket\n",
    "    bucket = session.resource(\"s3\").Bucket(b)\n",
    "    bucket.objects.all().delete()\n",
    "    sleep(5)\n",
    "\n",
    "    # Delete the S3 Bucket\n",
    "    s3.delete_bucket(Bucket=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Steps\n",
    "\n",
    "Congratulations! You've successfully cleaned up the default POC objects from your account. If you created additional Dataset Groups or other resources that were not included in the default POC, be sure to clean those up manually or modify the scripts above to clean them up for you.\n",
    "\n",
    "The final step is to go back to the CloudFormation console and delete the Stack you provisioned to create these notebooks.\n",
    "\n",
    "We hope you enjoyed learning how to predict the future with AWS Forecast."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
